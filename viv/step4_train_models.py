#!/usr/bin/env python3
"""
Task 5 - æ­¥éª¤ 4/7: è®­ç»ƒæ¨¡å‹ï¼ˆç®€åŒ–ç‰ˆï¼‰

è®­ç»ƒå¤šä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹å¹¶æ¯”è¾ƒæ€§èƒ½
"""

import sys
import pandas as pd
import os
import pickle
import warnings
warnings.filterwarnings('ignore')

print("=" * 80)
print("Task 5 - æ­¥éª¤ 4/7: è®­ç»ƒæ¨¡å‹")
print("=" * 80)
print()

# æ£€æŸ¥è¾“å…¥æ–‡ä»¶
required_files = ["X_train.csv", "y_train.csv", "X_test.csv", "y_test.csv"]
missing_files = [f for f in required_files if not os.path.exists(f)]

if missing_files:
    print(f"âŒ é”™è¯¯: ç¼ºå°‘å¿…è¦æ–‡ä»¶:")
    for f in missing_files:
        print(f"  - {f}")
    print()
    print("è¯·å…ˆè¿è¡Œ: python step3_preprocess_data.py")
    sys.exit(1)

print("âœ… æ‰¾åˆ°æ‰€æœ‰å¿…è¦æ–‡ä»¶")
print()

# åŠ è½½æ•°æ®
print("ğŸ“‚ åŠ è½½è®­ç»ƒå’Œæµ‹è¯•æ•°æ®...")
X_train = pd.read_csv("X_train.csv")
y_train = pd.read_csv("y_train.csv").squeeze()
X_test = pd.read_csv("X_test.csv")
y_test = pd.read_csv("y_test.csv").squeeze()

print(f"è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬, {len(X_train.columns)} ç‰¹å¾")
print(f"æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
print()

# å¯¼å…¥æ¨¡å‹
print("ğŸ”§ åˆå§‹åŒ–æ¨¡å‹...")
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# æ£€æŸ¥XGBoost
try:
    import xgboost as xgb
    HAS_XGBOOST = True
    print("âœ… XGBoost å¯ç”¨")
except:
    HAS_XGBOOST = False
    print("âš ï¸  XGBoost ä¸å¯ç”¨ï¼ˆè·³è¿‡ï¼‰")

print()

# è®­ç»ƒæ¨¡å‹
print("=" * 80)
print("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹")
print("=" * 80)
print()

models = {
    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),
    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)
}

if HAS_XGBOOST:
    models['XGBoost'] = xgb.XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss')

print(f"å°†è®­ç»ƒ {len(models)} ä¸ªæ¨¡å‹:")
for i, name in enumerate(models.keys(), 1):
    print(f"  {i}. {name}")
print()
print("â±ï¸  é¢„è®¡æ—¶é—´: 5-10åˆ†é’Ÿ")
print()

# è®­ç»ƒå¹¶è¯„ä¼°
results = {}

for i, (name, model) in enumerate(models.items(), 1):
    print(f"[{i}/{len(models)}] è®­ç»ƒ {name}...")
    
    try:
        # è®­ç»ƒ
        model.fit(X_train, y_train)
        
        # é¢„æµ‹
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else y_pred
        
        # è¯„ä¼°
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, zero_division=0)
        recall = recall_score(y_test, y_pred, zero_division=0)
        f1 = f1_score(y_test, y_pred, zero_division=0)
        
        try:
            roc_auc = roc_auc_score(y_test, y_pred_proba)
        except:
            roc_auc = 0.5
        
        results[name] = {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'roc_auc': roc_auc
        }
        
        print(f"   âœ… å®Œæˆ - å‡†ç¡®åº¦: {accuracy:.4f}")
        
        # ä¿å­˜æ¨¡å‹
        model_filename = f"trained_model_{name.lower().replace(' ', '_')}.pkl"
        with open(model_filename, 'wb') as f:
            pickle.dump(model, f)
        
    except Exception as e:
        print(f"   âŒ å¤±è´¥: {str(e)[:50]}")
        results[name] = {
            'accuracy': 0,
            'precision': 0,
            'recall': 0,
            'f1': 0,
            'roc_auc': 0
        }

print()
print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")
print()

# æ˜¾ç¤ºç»“æœ
print("=" * 80)
print("ğŸ“Š æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ")
print("=" * 80)
print()

# åˆ›å»ºç»“æœè¡¨æ ¼
results_df = pd.DataFrame(results).T
results_df = results_df.round(4)

# æŒ‰å‡†ç¡®åº¦æ’åº
results_df = results_df.sort_values('accuracy', ascending=False)

print(results_df.to_string())
print()

# æ‰¾å‡ºæœ€ä½³æ¨¡å‹
best_model_name = results_df['accuracy'].idxmax()
best_accuracy = results_df.loc[best_model_name, 'accuracy']

print(f"ğŸ† æœ€ä½³æ¨¡å‹: {best_model_name}")
print(f"   å‡†ç¡®åº¦: {best_accuracy:.4f}")
print(f"   F1åˆ†æ•°: {results_df.loc[best_model_name, 'f1']:.4f}")
print(f"   ROC-AUC: {results_df.loc[best_model_name, 'roc_auc']:.4f}")
print()

# æ¨¡å‹è§£é‡Š
print("=" * 80)
print("ğŸ“– æŒ‡æ ‡è¯´æ˜")
print("=" * 80)
print()

print("Accuracy (å‡†ç¡®åº¦): é¢„æµ‹æ­£ç¡®çš„æ¯”ä¾‹")
print("Precision (ç²¾ç¡®ç‡): é¢„æµ‹ä¸ºé˜³æ€§ä¸­å®é™…ä¸ºé˜³æ€§çš„æ¯”ä¾‹")
print("Recall (å¬å›ç‡): å®é™…é˜³æ€§ä¸­è¢«æ­£ç¡®é¢„æµ‹çš„æ¯”ä¾‹")
print("F1-Score: ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡")
print("ROC-AUC: æ¨¡å‹åŒºåˆ†èƒ½åŠ›çš„ç»¼åˆæŒ‡æ ‡ (è¶Šæ¥è¿‘1è¶Šå¥½)")
print()

# åˆ†æç»“æœ
print("=" * 80)
print("ğŸ’¡ ç»“æœåˆ†æ")
print("=" * 80)
print()

print("æ¨¡å‹æ€§èƒ½è¯„ä¼°:")
if best_accuracy >= 0.8:
    print("  ğŸŒŸ ä¼˜ç§€: æ¨¡å‹æ€§èƒ½å¾ˆå¥½")
elif best_accuracy >= 0.7:
    print("  âœ… è‰¯å¥½: æ¨¡å‹æ€§èƒ½ä¸é”™")
elif best_accuracy >= 0.6:
    print("  âš ï¸  ä¸€èˆ¬: æ¨¡å‹æ€§èƒ½ä¸­ç­‰")
else:
    print("  âŒ è¾ƒå·®: å¯èƒ½éœ€è¦æ›´å¤šç‰¹å¾å·¥ç¨‹")
print()

# ç‰¹å¾é‡è¦æ€§ï¼ˆå¦‚æœæ˜¯æ ‘æ¨¡å‹ï¼‰
print("=" * 80)
print("ğŸ” ç‰¹å¾é‡è¦æ€§ï¼ˆæœ€ä½³æ¨¡å‹ï¼‰")
print("=" * 80)
print()

best_model_file = f"trained_model_{best_model_name.lower().replace(' ', '_')}.pkl"
if os.path.exists(best_model_file):
    with open(best_model_file, 'rb') as f:
        best_model = pickle.load(f)
    
    if hasattr(best_model, 'feature_importances_'):
        # æ ‘æ¨¡å‹
        feature_importance = pd.DataFrame({
            'feature': X_train.columns,
            'importance': best_model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("Top 10 é‡è¦ç‰¹å¾:")
        print(feature_importance.head(10).to_string(index=False))
        
        # ä¿å­˜ç‰¹å¾é‡è¦æ€§
        feature_importance.to_csv("feature_importance.csv", index=False)
        print()
        print("âœ… å·²ä¿å­˜: feature_importance.csv")
        
    elif hasattr(best_model, 'coef_'):
        # çº¿æ€§æ¨¡å‹
        feature_importance = pd.DataFrame({
            'feature': X_train.columns,
            'importance': abs(best_model.coef_[0])
        }).sort_values('importance', ascending=False)
        
        print("Top 10 é‡è¦ç‰¹å¾:")
        print(feature_importance.head(10).to_string(index=False))
        
        # ä¿å­˜ç‰¹å¾é‡è¦æ€§
        feature_importance.to_csv("feature_importance.csv", index=False)
        print()
        print("âœ… å·²ä¿å­˜: feature_importance.csv")
    else:
        print("âš ï¸  è¯¥æ¨¡å‹ä¸æ”¯æŒç›´æ¥æå–ç‰¹å¾é‡è¦æ€§")
else:
    print("âš ï¸  æ— æ³•åŠ è½½æœ€ä½³æ¨¡å‹æ–‡ä»¶")

print()

# ä¿å­˜ç»“æœ
print("ğŸ’¾ ä¿å­˜ç»“æœ...")
results_df.to_csv("model_comparison.csv")
print("âœ… å·²ä¿å­˜: model_comparison.csv")
print()

# æ€»ç»“
print("=" * 80)
print("âœ… æ­¥éª¤4å®Œæˆ - æ¨¡å‹è®­ç»ƒå®Œæ¯•")
print("=" * 80)
print()

print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
print("  1. model_comparison.csv - æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ")
print("  2. trained_model_*.pkl - è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶")
if os.path.exists("feature_importance.csv"):
    print("  3. feature_importance.csv - ç‰¹å¾é‡è¦æ€§")
print()

print("ğŸ¯ ä¸‹ä¸€æ­¥:")
print("  è¿è¡Œ: python step5_analyze_features.py")
print("  ä½œç”¨: è¯¦ç»†åˆ†æç‰¹å¾é‡è¦æ€§")
print()

print("ğŸ’¡ æç¤º:")
print(f"  æ‚¨å¯ä»¥æŸ¥çœ‹æ¨¡å‹æ€§èƒ½: open model_comparison.csv")
print()

