#!/usr/bin/env python3
"""
Task 5 - æ­¥éª¤6: ç»“æœå¯è§†åŒ–

ç”Ÿæˆå®Œæ•´çš„ç»“æœå¯è§†åŒ–æŠ¥å‘Š
"""

import sys
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns

print("=" * 80)
print("Task 5 - æ­¥éª¤ 6/7: ç»“æœå¯è§†åŒ–")
print("=" * 80)
print()

# è®¾ç½®ç»˜å›¾é£æ ¼
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 8)

# æ£€æŸ¥è¾“å…¥æ–‡ä»¶
required_files = {
    "model_comparison.csv": "æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ",
    "feature_importance.csv": "ç‰¹å¾é‡è¦æ€§",
    "y_test.csv": "æµ‹è¯•æ ‡ç­¾"
}

missing_files = [f for f, desc in required_files.items() if not os.path.exists(f)]

if missing_files:
    print(f"âŒ é”™è¯¯: ç¼ºå°‘å¿…è¦æ–‡ä»¶:")
    for f in missing_files:
        print(f"  - {f}")
    print()
    print("è¯·ç¡®ä¿å·²è¿è¡Œå‰é¢çš„æ­¥éª¤")
    sys.exit(1)

print("âœ… æ‰¾åˆ°æ‰€æœ‰å¿…è¦æ–‡ä»¶")
print()

# 1. æ¨¡å‹æ€§èƒ½æ¯”è¾ƒå›¾
print("=" * 80)
print("ğŸ“Š 1. æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ")
print("=" * 80)
print()

model_results = pd.read_csv("model_comparison.csv", index_col=0)

fig, axes = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle('Model Performance Comparison', fontsize=16, y=1.00)

metrics = ['accuracy', 'precision', 'recall', 'f1']
titles = ['Accuracy', 'Precision', 'Recall', 'F1-Score']

for idx, (metric, title) in enumerate(zip(metrics, titles)):
    ax = axes[idx // 2, idx % 2]
    
    if metric in model_results.columns:
        data = model_results[metric].sort_values()
        bars = ax.barh(range(len(data)), data.values)
        ax.set_yticks(range(len(data)))
        ax.set_yticklabels(data.index)
        ax.set_xlabel(title)
        ax.set_xlim([0, 1])
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, value) in enumerate(zip(bars, data.values)):
            ax.text(value + 0.02, i, f'{value:.3f}', va='center')

plt.tight_layout()
plt.savefig('model_performance_comparison.png', dpi=300, bbox_inches='tight')
print("âœ… å·²ä¿å­˜: model_performance_comparison.png")
print()

# 2. ç‰¹å¾é‡è¦æ€§å›¾
print("=" * 80)
print("ğŸ“Š 2. ç‰¹å¾é‡è¦æ€§")
print("=" * 80)
print()

feature_imp = pd.read_csv("feature_importance.csv")

plt.figure(figsize=(10, 8))
top_n = min(15, len(feature_imp))
top_features = feature_imp.head(top_n)

plt.barh(range(top_n), top_features['importance'])
plt.yticks(range(top_n), top_features['feature'])
plt.xlabel('Importance Score')
plt.title(f'Top {top_n} Most Important Features')
plt.gca().invert_yaxis()
plt.tight_layout()

plt.savefig('top_features.png', dpi=300, bbox_inches='tight')
print("âœ… å·²ä¿å­˜: top_features.png")
print()

# 3. æ•°æ®åˆ†å¸ƒå›¾
print("=" * 80)
print("ğŸ“Š 3. æ•°æ®åˆ†å¸ƒåˆ†æ")
print("=" * 80)
print()

if os.path.exists("preprocessed_data.csv"):
    df = pd.read_csv("preprocessed_data.csv")
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle('Data Distribution Analysis', fontsize=16)
    
    # å¹´é¾„åˆ†å¸ƒ
    if 'age_years' in df.columns or 'patientonsetage' in df.columns:
        age_col = 'age_years' if 'age_years' in df.columns else 'patientonsetage'
        age_data = pd.to_numeric(df[age_col], errors='coerce').dropna()
        if len(age_data) > 0:
            axes[0, 0].hist(age_data, bins=30, edgecolor='black')
            axes[0, 0].set_xlabel('Age (years)')
            axes[0, 0].set_ylabel('Count')
            axes[0, 0].set_title('Age Distribution')
    
    # æ€§åˆ«åˆ†å¸ƒ
    if 'patientsex' in df.columns:
        sex_counts = df['patientsex'].value_counts()
        sex_labels = {1: 'Male', 2: 'Female', 0: 'Unknown'}
        labels = [sex_labels.get(x, f'Code {x}') for x in sex_counts.index]
        axes[0, 1].bar(range(len(sex_counts)), sex_counts.values)
        axes[0, 1].set_xticks(range(len(sex_counts)))
        axes[0, 1].set_xticklabels(labels)
        axes[0, 1].set_ylabel('Count')
        axes[0, 1].set_title('Gender Distribution')
    
    # è¯ç‰©æ•°é‡åˆ†å¸ƒ
    if 'num_drugs' in df.columns:
        drug_counts = df['num_drugs'].value_counts().sort_index()
        axes[1, 0].bar(drug_counts.index, drug_counts.values)
        axes[1, 0].set_xlabel('Number of Drugs')
        axes[1, 0].set_ylabel('Count')
        axes[1, 0].set_title('Polypharmacy Distribution')
    
    # ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ
    if 'seriousnessdeath' in df.columns:
        death_counts = pd.to_numeric(df['seriousnessdeath'], errors='coerce').value_counts()
        labels = ['No Death', 'Death']
        axes[1, 1].bar(range(len(death_counts)), death_counts.values)
        axes[1, 1].set_xticks(range(len(death_counts)))
        axes[1, 1].set_xticklabels(labels)
        axes[1, 1].set_ylabel('Count')
        axes[1, 1].set_title('Outcome Distribution')
    
    plt.tight_layout()
    plt.savefig('data_distribution.png', dpi=300, bbox_inches='tight')
    print("âœ… å·²ä¿å­˜: data_distribution.png")
    print()

# ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
print("=" * 80)
print("ğŸ“ ç”Ÿæˆæ€»ç»“æŠ¥å‘Š")
print("=" * 80)
print()

with open("RESULTS_SUMMARY.txt", "w") as f:
    f.write("=" * 80 + "\n")
    f.write("Task 5: Adverse Event Severity Prediction - Results Summary\n")
    f.write("=" * 80 + "\n\n")
    
    # æ•°æ®æ¦‚è§ˆ
    if os.path.exists("epcoritamab_data.csv"):
        df_raw = pd.read_csv("epcoritamab_data.csv")
        f.write(f"1. Data Overview\n")
        f.write(f"   Total Records: {len(df_raw)}\n")
        f.write(f"   Total Features: {len(df_raw.columns)}\n\n")
    
    # æ¨¡å‹æ€§èƒ½
    f.write(f"2. Model Performance\n\n")
    f.write(model_results.to_string())
    f.write("\n\n")
    
    # æœ€ä½³æ¨¡å‹
    best_model = model_results['accuracy'].idxmax()
    best_acc = model_results.loc[best_model, 'accuracy']
    f.write(f"3. Best Model\n")
    f.write(f"   Model: {best_model}\n")
    f.write(f"   Accuracy: {best_acc:.4f}\n\n")
    
    # Topç‰¹å¾
    f.write(f"4. Top 10 Most Important Features\n\n")
    f.write(feature_imp.head(10).to_string(index=False))
    f.write("\n\n")
    
    f.write("=" * 80 + "\n")
    f.write("End of Summary\n")
    f.write("=" * 80 + "\n")

print("âœ… å·²ä¿å­˜: RESULTS_SUMMARY.txt")
print()

# åˆ—å‡ºæ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶
print("=" * 80)
print("âœ… æ­¥éª¤6å®Œæˆ - å¯è§†åŒ–å®Œæ¯•")
print("=" * 80)
print()

print("ğŸ“ ç”Ÿæˆçš„å¯è§†åŒ–æ–‡ä»¶:")
print("  1. model_performance_comparison.png - æ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾")
print("  2. top_features.png - é‡è¦ç‰¹å¾å›¾")
print("  3. data_distribution.png - æ•°æ®åˆ†å¸ƒå›¾")
print("  4. RESULTS_SUMMARY.txt - ç»“æœæ€»ç»“æŠ¥å‘Š")
print()

print("ğŸ’¡ æŸ¥çœ‹ç»“æœ:")
print("  æŸ¥çœ‹å›¾ç‰‡: open model_performance_comparison.png")
print("  æŸ¥çœ‹æŠ¥å‘Š: open RESULTS_SUMMARY.txt")
print()

print("=" * 80)
print("ğŸ‰ æ­å–œï¼Task 5 å…¨éƒ¨å®Œæˆï¼")
print("=" * 80)
print()

print("ğŸ“‹ å®Œæ•´çš„è¾“å‡ºæ–‡ä»¶æ¸…å•:")
print()
print("æ•°æ®æ–‡ä»¶:")
print("  âœ“ epcoritamab_data.csv - åŸå§‹æ•°æ®")
print("  âœ“ preprocessed_data.csv - é¢„å¤„ç†æ•°æ®")
print("  âœ“ X_train.csv, y_train.csv - è®­ç»ƒé›†")
print("  âœ“ X_test.csv, y_test.csv - æµ‹è¯•é›†")
print()

print("æ¨¡å‹æ–‡ä»¶:")
model_files = [f for f in os.listdir('.') if f.startswith('trained_model_')]
for f in model_files:
    print(f"  âœ“ {f}")
print()

print("ç»“æœæ–‡ä»¶:")
print("  âœ“ model_comparison.csv - æ¨¡å‹æ€§èƒ½è¡¨")
print("  âœ“ feature_importance.csv - ç‰¹å¾é‡è¦æ€§è¡¨")
print()

print("å¯è§†åŒ–æ–‡ä»¶:")
print("  âœ“ model_performance_comparison.png")
print("  âœ“ top_features.png")
print("  âœ“ data_distribution.png")
print("  âœ“ feature_importance.png")
print()

print("æŠ¥å‘Šæ–‡ä»¶:")
print("  âœ“ RESULTS_SUMMARY.txt")
print()

print("ğŸ¯ åç»­å·¥ä½œå»ºè®®:")
print("  1. æŸ¥çœ‹RESULTS_SUMMARY.txtäº†è§£æ•´ä½“ç»“æœ")
print("  2. æ£€æŸ¥å¯è§†åŒ–å›¾è¡¨ç†è§£æ¨¡å‹è¡¨ç°")
print("  3. æ ¹æ®ç‰¹å¾é‡è¦æ€§ä¼˜åŒ–æ¨¡å‹")
print("  4. å‡†å¤‡é¡¹ç›®æŠ¥å‘Šå’Œå±•ç¤ºææ–™")
print()

